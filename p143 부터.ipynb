{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 정확도  \n",
    "+ 오차행렬  \n",
    "+ 정밀도  \n",
    "+ 재현율  \n",
    "+ F1 스코어  \n",
    "+ ROC, AUC  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도\n",
    "+ 실제 데이터에서 예측 데이터가 얼만가 같은지 판단하는 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class mydummyclassifier(BaseEstimator):\n",
    "    def fit(self,X,y=None):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        pred=np.zeros((X.shape[0],1))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i]==1:\n",
    "                pred[i]=0\n",
    "            else:\n",
    "                pred[i]=1\n",
    "            \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mydummy의 정확도는 0.3855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "#원본 데이터 재로딩,데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "\n",
    "data=pd.read_csv('titanic.csv')\n",
    "y=data['Survived']\n",
    "x=data.drop('Survived',axis=1)\n",
    "#x=transform_features(x)\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "\n",
    "myclf=mydummyclassifier()\n",
    "myclf.fit(X_train,y_train)\n",
    "\n",
    "prediction=myclf.predict(X_test)\n",
    "print(f'mydummy의 정확도는 {round(accuracy_score(y_test,prediction),4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST 데이터셋을 변환해 정확도 분류해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class myfakeclassifier(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1),dtype=bool)\n",
    "    \n",
    "digit=load_digits()\n",
    "\n",
    "y=(digit.target==7).astype(int)\n",
    "X_train,X_test,y_train,y_test=train_test_split(digit.data,y,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 크기 (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는 0.9\n"
     ]
    }
   ],
   "source": [
    "# 불균형 레이블 분포도 확인\n",
    "\n",
    "print(f'레이블 테스트 크기 {y_test.shape}')\n",
    "print(f'테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "#dummyclassifier로 평가\n",
    "\n",
    "fakeclf=myfakeclassifier()\n",
    "fakeclf.fit(X_train,y_test)\n",
    "predict=fakeclf.predict(X_test)\n",
    "print(f'모든 예측을 0으로 하여도 정확도는 {accuracy_score(y_test,predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단순히 predict() 결과를 모두 0으로 반환해도 성능이 90%나온다.\n",
    "##### 불균형한 데이터셋에서 정확도 지표는 옳지 못한 선택임을 알 수있으며\n",
    "##### 이를 위해 다른 여러 지표를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오차 행렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 모델이 얼마나 헷갈리고 있는지도 함께 보여주는 지표\n",
    "+ 예측 오류가 얼마인지, 어떤 오류가 발생하는지도 나타냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# ![title](matrix.png)  마크다운 형식으로 이미지 삽입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](matrix_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정밀도와 재현율\n",
    "\n",
    "+ Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가지표\n",
    "    + 정밀도 = TP/(FP+TP)\n",
    "    + 재현율 = TP/(FN+TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test,pred):\n",
    "    confusion=confusion_matrix(y_test,pred)\n",
    "    accuracy=accuracy_score(y_test,pred)\n",
    "    precision=precision_score(y_test,pred)\n",
    "    recall=recall_score(y_test,pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print(f'정확도: {round(accuracy,4)}, 정밀도: {round(precision,4)}, 재현율: {round(recall,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def fillna(data):\n",
    "    data['Age'].fillna(data['Age'].mean(),inplace=True)\n",
    "    data['Cabin'].fillna('N',inplace=True)\n",
    "    data['Embarked'].fillna('N',inplace=True)\n",
    "    data['Fare'].fillna(0,inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def drop(data):\n",
    "    data.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return data\n",
    "\n",
    "def format_feature(data):\n",
    "    data['Cabin']=data['Cabin'].str[:1]\n",
    "    features=['Cabin','Sex','Embarked']\n",
    "    for i in features:\n",
    "        le=preprocessing.LabelEncoder()\n",
    "        le=le.fit(data[i])\n",
    "        data[i]=le.transform(data[i])\n",
    "    return data\n",
    "\n",
    "#함수들 호출해 전처리 수행\n",
    "\n",
    "def transform(data):\n",
    "    data=fillna(data)\n",
    "    data=drop(data)\n",
    "    data=format_feature(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[108  10]\n",
      " [ 14  47]]\n",
      "정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data=pd.read_csv('titanic.csv')\n",
    "y=data['Survived']\n",
    "x=data.drop('Survived',axis=1)\n",
    "x=transform(x)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=11)\n",
    "\n",
    "lr_clf=LogisticRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "pred=lr_clf.predict(X_test)\n",
    "\n",
    "get_clf_eval(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 매번 데이터셋을 전처리 할 순 없으니 x,y를 합친 preprocessing을 내보내서 활용할 예정..\n",
    " + x['Survived']=y\n",
    " + x.to_csv('preprocessing.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
